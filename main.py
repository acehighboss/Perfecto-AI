import streamlit as st
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
from dotenv import load_dotenv

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()


# --- ìƒˆë¡œìš´ ê¸°ëŠ¥: í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸ ---
def get_keyword_extraction_chain():
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” LLM ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_template(
        """
        Analyze the following text and extract the 10 most important and relevant keywords or key phrases.
        The keywords should accurately represent the main topics of the text.
        Please provide the result as a single comma-separated string.

        Example:
        Text: "The James Webb Space Telescope (JWST) is a space telescope designed primarily to conduct infrared astronomy..."
        Keywords: James Webb Space Telescope, infrared astronomy, space telescope, JWST, cosmic history, Big Bang, galaxy formation, exoplanets, NASA, deep space

        Text to analyze:
        {text}

        Keywords:
        """
    )
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0)
    chain = prompt | llm | StrOutputParser()
    return chain


# --- RAG íŒŒì´í”„ë¼ì¸ ê´€ë ¨ í•¨ìˆ˜ (ìˆ˜ì •ë¨) ---
@st.cache_resource(show_spinner="ì›¹ì‚¬ì´íŠ¸ë¥¼ ë¶„ì„í•˜ê³  í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤...")
def process_url_and_get_components(url):
    """
    URLë¡œë¶€í„° ë¬¸ì„œë¥¼ ë¡œë“œ, ë¶„í• í•˜ê³  retrieverì™€ ì›ë³¸ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. ë¬¸ì„œ ë¡œë“œ
    loader = WebBaseLoader(url)
    documents = loader.load()

    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    splits = text_splitter.split_documents(documents)

    # 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(splits, embeddings)

    # 4. Retrieverì™€ ë¶„í• ëœ ë¬¸ì„œ(splits)ë¥¼ í•¨ê»˜ ë°˜í™˜
    return vectorstore.as_retriever(search_kwargs={"k": 5}), splits


# --- ê¸°ì¡´ ì²´ì¸ ìƒì„± í•¨ìˆ˜ë“¤ ---
def get_conversational_rag_chain(retriever):
    rag_prompt = ChatPromptTemplate.from_template(
        """Answer the user's question based on the context provided below. If you don't know the answer, just say that you don't know.
        Context: {context}
        Question: {input}"""
    )
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0)
    document_chain = create_stuff_documents_chain(llm, rag_prompt)
    return create_retrieval_chain(retriever, document_chain)


def get_default_chain():
    prompt = ChatPromptTemplate.from_messages(
        [("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."), ("user", "{question}")]
    )
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0)
    return prompt | llm | StrOutputParser()


# --- Streamlit ì•± UI ë° ë¡œì§ ---
st.set_page_config(page_title="Keyword-Extracting RAG Chatbot", page_icon="ğŸ”‘")
st.title("ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ RAG ì±—ë´‡")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "keywords" not in st.session_state:
    st.session_state.keywords = []

# --- ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("RAG ì„¤ì •")
    url_input = st.text_input(
        "ë¶„ì„í•  ì›¹ì‚¬ì´íŠ¸ URLì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="https://example.com"
    )

    if st.button("ì‚¬ì´íŠ¸ ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ"):
        if url_input:
            # URL ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ retrieverì™€ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
            retriever, documents = process_url_and_get_components(url_input)
            st.session_state.retriever = retriever

            # í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§
            if documents:
                # ëª¨ë“  ë¬¸ì„œì˜ ë‚´ìš©ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
                full_text = " ".join([doc.page_content for doc in documents])
                # í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸ ì‹¤í–‰
                keyword_chain = get_keyword_extraction_chain()
                keyword_string = keyword_chain.invoke({"text": full_text})
                # ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ê³  ê³µë°± ì œê±°í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦
                st.session_state.keywords = [
                    keyword.strip() for keyword in keyword_string.split(",")
                ]

            st.success("ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ!")
        else:
            st.warning("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
    if st.session_state.keywords:
        st.divider()
        st.subheader("ì¶”ì¶œëœ í•µì‹¬ í‚¤ì›Œë“œ")
        # st.chipì„ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œë¥¼ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
        for keyword in st.session_state.keywords:
            st.chip(keyword, icon="ğŸ”‘")

    st.divider()
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

# --- ë©”ì¸ ì±„íŒ… í™”ë©´ ---
# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
if "messages" in st.session_state:
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

if user_input:
    st.chat_message("user").write(user_input)

    # RAG ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if st.session_state.retriever:
        chain = get_conversational_rag_chain(st.session_state.retriever)
        response = chain.stream({"input": user_input})

        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for chunk in response:
                if "answer" in chunk:
                    ai_answer += chunk["answer"]
                    container.markdown(ai_answer)
    else:
        # RAG ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ëœ ê²½ìš°, ê¸°ë³¸ ì²´ì¸ ì‚¬ìš©
        chain = get_default_chain()
        response = chain.stream({"question": user_input})

        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for token in response:
                ai_answer += token
                container.markdown(ai_answer)

    # ëŒ€í™”ê¸°ë¡ ì €ì¥
    st.session_state.messages.append(ChatMessage(role="user", content=user_input))
    st.session_state.messages.append(ChatMessage(role="assistant", content=ai_answer))
