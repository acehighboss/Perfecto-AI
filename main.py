import streamlit as st
from file_handler import FileHandler
from rag_pipeline import RAGPipeline

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="RAG ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'rag_pipeline' not in st.session_state:
    st.session_state.rag_pipeline = None
if 'file_handler' not in st.session_state:
    st.session_state.file_handler = None
if 'documents_processed' not in st.session_state:
    st.session_state.documents_processed = False
if 'system_prompt' not in st.session_state:
    st.session_state.system_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."

def initialize_components():
    """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    try:
        google_api_key = st.secrets["GOOGLE_API_KEY"]
        llama_api_key = st.secrets["LLAMA_API_KEY"]
    except KeyError as e:
        st.error(f"Streamlit secretsì—ì„œ {e} í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    if st.session_state.rag_pipeline is None:
        st.session_state.rag_pipeline = RAGPipeline(google_api_key)
    
    if st.session_state.file_handler is None:
        st.session_state.file_handler = FileHandler(llama_api_key)

def main():
    st.title("ğŸ¤– RAG ì±—ë´‡")
    st.markdown("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
    
    # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    initialize_components()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        st.subheader("ğŸ­ í˜ë¥´ì†Œë‚˜ ì„¤ì •")
        new_system_prompt = st.text_area(
            "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
            value=st.session_state.system_prompt,
            height=100,
            help="ì±—ë´‡ì˜ ì„±ê²©ê³¼ ë‹µë³€ ìŠ¤íƒ€ì¼ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        if st.button("í”„ë¡¬í”„íŠ¸ ì ìš©", type="primary"):
            st.session_state.system_prompt = new_system_prompt
            st.success("í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        st.divider()
        
        # 2. íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
        st.subheader("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        # URL ì…ë ¥
        url_input = st.text_input("URL ì…ë ¥:", placeholder="https://example.com")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_files = st.file_uploader(
            "íŒŒì¼ ì—…ë¡œë“œ:",
            type=['pdf', 'docx', 'doc', 'txt'],
            accept_multiple_files=True,
            help="PDF, Word, í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        # 3. ë¶„ì„ ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸ“Š ë¶„ì„ ì‹œì‘", type="primary"):
            if not url_input and not uploaded_files:
                st.warning("URL ë˜ëŠ” íŒŒì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                process_documents(url_input, uploaded_files)
        
        # 4. ë¶„ì„ ìƒíƒœ í‘œì‹œ
        st.subheader("ğŸ“ˆ ë¶„ì„ ìƒíƒœ")
        doc_count = st.session_state.rag_pipeline.get_document_count() if st.session_state.rag_pipeline else 0
        
        if doc_count > 0:
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ ({doc_count}ê°œ ì²­í¬)")
            st.session_state.documents_processed = True
        else:
            st.info("â³ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")
            st.session_state.documents_processed = False
        
        st.divider()
        
        # 5. ì´ˆê¸°í™” ë²„íŠ¼
        st.subheader("ğŸ”„ ì´ˆê¸°í™”")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ëŒ€í™” ì´ˆê¸°í™”", help="ì±„íŒ… ê¸°ë¡ì„ ì‚­ì œí•©ë‹ˆë‹¤"):
                st.session_state.messages = []
                st.rerun()
        
        with col2:
            if st.button("ì „ì²´ ì´ˆê¸°í™”", help="ëª¨ë“  ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤"):
                st.session_state.messages = []
                if st.session_state.rag_pipeline:
                    st.session_state.rag_pipeline.clear_database()
                st.session_state.documents_processed = False
                st.rerun()
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    chat_container = st.container()
    
    with chat_container:
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            if not st.session_state.documents_processed:
                st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
                return
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
                    similar_docs = st.session_state.rag_pipeline.search_similar_documents(prompt)
                    
                    if similar_docs:
                        # ë‹µë³€ ìƒì„±
                        response = st.session_state.rag_pipeline.generate_answer(
                            prompt, 
                            similar_docs, 
                            st.session_state.system_prompt
                        )
                        st.markdown(response)
                        
                        # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
                        with st.expander("ğŸ“š ì°¸ê³ í•œ ë¬¸ì„œë“¤"):
                            for i, doc in enumerate(similar_docs, 1):
                                st.markdown(f"**[ì¶œì²˜ {i}]** {doc['source']}")
                                st.markdown(f"```\n{doc['content'][:300]}...\n```")
                                st.markdown(f"*ìœ ì‚¬ë„: {doc['similarity']:.3f}*")
                                st.divider()
                    else:
                        response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        st.markdown(response)
                
                # ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
                st.session_state.messages.append({"role": "assistant", "content": response})

def process_documents(url_input, uploaded_files):
    """ë¬¸ì„œ ì²˜ë¦¬ í•¨ìˆ˜"""
    with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        success_count = 0
        total_count = 0
        
        # URL ì²˜ë¦¬
        if url_input:
            total_count += 1
            text = st.session_state.file_handler.extract_text_from_url(url_input)
            if text:
                chunks = st.session_state.file_handler.chunk_text(text)
                if st.session_state.rag_pipeline.add_documents(chunks, f"URL: {url_input}"):
                    success_count += 1
        
        # íŒŒì¼ ì²˜ë¦¬
        if uploaded_files:
            for uploaded_file in uploaded_files:
                total_count += 1
                text = st.session_state.file_handler.process_file(uploaded_file)
                if text:
                    chunks = st.session_state.file_handler.chunk_text(text)
                    if st.session_state.rag_pipeline.add_documents(chunks, f"íŒŒì¼: {uploaded_file.name}"):
                        success_count += 1
        
        if success_count > 0:
            st.success(f"âœ… {success_count}/{total_count}ê°œ ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.session_state.documents_processed = True
        else:
            st.error("âŒ ë¬¸ì„œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
